{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shwethailango/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shwethailango/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/shwethailango/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import nltk;\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import pyLDAvis.gensim\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "import pyLDAvis\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, sentiwordnet as swn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import ngrams\n",
    "from rake_nltk import Rake\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import collections\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from stopwords_list import stop_words_list\n",
    "#from wn_affect import wn_affect \n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from pyLDAvis import sklearn as sklearn_lda\n",
    "from spacy.lang.en import English\n",
    "import string\n",
    "import re\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "#!pip install en\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters & k-number of topics\n",
    "k = 20\n",
    "init = 'k-means++'\n",
    "max_iter = 700\n",
    "n_init = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review\n",
       "0                             Wow... Loved this place.\n",
       "1                                   Crust is not good.\n",
       "2            Not tasty and the texture was just nasty.\n",
       "3    Stopped by during the late May bank holiday of...\n",
       "4    The selection on the menu was great and so wer...\n",
       "..                                                 ...\n",
       "995  I think food should have flavor and texture an...\n",
       "996                           Appetite instantly gone.\n",
       "997  Overall I was not impressed and would not go b...\n",
       "998  The whole experience was underwhelming, and I ...\n",
       "999  Then, as if I hadn't wasted enough of my life ...\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('output.csv')\n",
    "train_df=df.drop(columns=['Liked'], axis=1)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = train_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review\n",
       "0                             Wow... Loved this place.\n",
       "1                                   Crust is not good.\n",
       "2            Not tasty and the texture was just nasty.\n",
       "3    Stopped by during the late May bank holiday of...\n",
       "4    The selection on the menu was great and so wer...\n",
       "..                                                 ...\n",
       "995  I think food should have flavor and texture an...\n",
       "996                           Appetite instantly gone.\n",
       "997  Overall I was not impressed and would not go b...\n",
       "998  The whole experience was underwhelming, and I ...\n",
       "999  Then, as if I hadn't wasted enough of my life ...\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Review'], dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en in /Users/shwethailango/opt/anaconda3/lib/python3.8/site-packages (0.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreProcessor():\n",
    "    \n",
    "    NLP = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    parser = English()\n",
    "    noisy_pos_tags = ['PROP']\n",
    "    min_token_length = 2\n",
    "\n",
    "\n",
    "    def stopWords():\n",
    "        spacy_stopwords = TextPreProcessor.NLP.Defaults.stop_words\n",
    "\n",
    "        stop_words = stopwords.words('english')\n",
    "        stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'need', 'able', 'bmc', 'com'])\n",
    "        \n",
    "        stop_words.extend(spacy_stopwords)\n",
    "        return stop_words\n",
    "\n",
    "    def removeStopWords(data):\n",
    "        STOP_WORDS = TextPreProcessor.stopWords()\n",
    "        cleanedData = []\n",
    "        for sent in data:\n",
    "            sent_cleaned = \"\"\n",
    "            for word in sent.split():\n",
    "                if word not in STOP_WORDS and word not in string.punctuation and len(word) > TextPreProcessor.min_token_length:\n",
    "                    sent_cleaned += word\n",
    "                    sent_cleaned += \" \"\n",
    "            cleanedData.append(sent_cleaned)\n",
    "        return cleanedData\n",
    "                     \n",
    "    def removePunctuation(data):\n",
    "        return [sent.translate(sent.maketrans(string.punctuation, ' '*len(string.punctuation))) for sent in data]\n",
    "    \n",
    "    def removeHostName(data):\n",
    "        cleanedData = []\n",
    "        for sent in data:\n",
    "            sent_cleaned = \"\"\n",
    "            for word in sent.split():\n",
    "                sent_cleaned += re.sub(r'^([A-Za-z0-9]\\.|[A-Za-z0-9][A-Za-z0-9-]{0,61}[A-Za-z0-9]\\.){1,3}[A-Za-z]{2,6}$', '', word)\n",
    "                sent_cleaned += \" \"\n",
    "            cleanedData.append(sent_cleaned)\n",
    "        return cleanedData\n",
    "    \n",
    "    def removeIPAddress(data):\n",
    "        cleanedData = []\n",
    "        for sent in data:\n",
    "            sent_cleaned = \"\"\n",
    "            for word in sent.split():\n",
    "                sent_cleaned += re.sub(r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$', '', word)\n",
    "                sent_cleaned += \" \"\n",
    "            cleanedData.append(sent_cleaned)\n",
    "        return cleanedData\n",
    "\n",
    "    def removeEmails(data):\n",
    "        return [re.sub(r'\\S*@\\S*\\s?', '', sent) for sent in data]\n",
    "\n",
    "    def removeNewLineCharacters(data):\n",
    "        return [re.sub(r'\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "    def removeDigits(data):\n",
    "        return [re.sub(r'\\d', ' ', sent) for sent in data]\n",
    "                \n",
    "    def toLower(data):\n",
    "        return [sent.lower() for sent in data]\n",
    "\n",
    "    def spacy_tokenizer(sent):\n",
    "        tokens = TextPreProcessor.parser(sent)\n",
    "        tokens = [tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_ for tok in tokens]\n",
    "        tokens = [tok for tok in tokens if (tok not in STOP_WORDS and tok not in string.punctuation)]     \n",
    "        return tokens\n",
    "\n",
    "\n",
    "    def lemmatization(data, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV', 'PROPN']):\n",
    "        stopWords = TextPreProcessor.stopWords()\n",
    "        texts_out = []\n",
    "        tokens_out = []\n",
    "        for sent in data:\n",
    "            #print(sent)\n",
    "            doc = TextPreProcessor.NLP(sent) \n",
    "            lemmed_string =''\n",
    "            tokens = []\n",
    "            for word in doc:\n",
    "                if word.pos_ in allowed_postags:\n",
    "                    if word.lemma_ == '-PRON-' or word.lemma_ in stopWords: \n",
    "                        continue \n",
    "                    else: \n",
    "                        lemmed_string = lemmed_string + ' ' + word.lemma_\n",
    "                        tokens.append(word.lemma_)\n",
    "            #print(lemmed_string)\n",
    "            texts_out.append(lemmed_string.strip())\n",
    "            tokens_out.append(tokens)\n",
    "        return tokens_out\n",
    "\n",
    "    @staticmethod\n",
    "    def cleanup(data):\n",
    "        data = TextPreProcessor.toLower(data)\n",
    "        data = TextPreProcessor.removeHostName(data)\n",
    "        data = TextPreProcessor.removeIPAddress(data)\n",
    "        data = TextPreProcessor.removeNewLineCharacters(data)\n",
    "        data = TextPreProcessor.removePunctuation(data)\n",
    "        data = TextPreProcessor.removeDigits(data)\n",
    "        data = TextPreProcessor.removeEmails(data)\n",
    "        data = TextPreProcessor.removeStopWords(data)\n",
    "        data = TextPreProcessor.lemmatization(data)\n",
    "        return data\n",
    "    \n",
    "    def __init__(self, df, columns, combine = False, dropCombinedColumns = False):\n",
    "        self.df = df\n",
    "        self.columns = columns\n",
    "        self.combine = combine\n",
    "        self.dropCombinedColumns = dropCombinedColumns\n",
    "        self.process()\n",
    "                  \n",
    "    def process(self):  \n",
    "        columnToProcess = self.columns                   \n",
    "        if self.combine:\n",
    "            self.df['combined'] = self.df[self.columns].apply(\n",
    "                                        lambda x: ','.join(x.astype(str)), axis=1)\n",
    "            if dropCombinedColumns:\n",
    "                self.df = self.df.drop(self.columns, axis=1)\n",
    "                columnToProcess = [\"combined\"]\n",
    "            else:\n",
    "                columnsToProcess.append(\"combined\")\n",
    "        for col in columnToProcess:\n",
    "            print(\"Processing column : \" + col)\n",
    "            colName = col + \"_clean\"\n",
    "            self.df[colName] = TextPreProcessor.cleanup(self.df[col])\n",
    "        display(self.df.head())\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def process(data_df):\n",
    "    preProcessor = TextPreProcessor(your_df, ['Review'])\n",
    "    clean_df = preProcessor.df\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing column : Review\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Review_clean</th>\n",
       "      <th>Description_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>[love, place]</td>\n",
       "      <td>love place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>[crust, good]</td>\n",
       "      <td>crust good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>[tasty, texture, nasty]</td>\n",
       "      <td>tasty texture nasty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>[stopped, late, bank, holiday, rick, steve, re...</td>\n",
       "      <td>stopped late bank holiday rick steve recommend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>[selection, menu, great, price]</td>\n",
       "      <td>selection menu great price</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  \\\n",
       "0                           Wow... Loved this place.   \n",
       "1                                 Crust is not good.   \n",
       "2          Not tasty and the texture was just nasty.   \n",
       "3  Stopped by during the late May bank holiday of...   \n",
       "4  The selection on the menu was great and so wer...   \n",
       "\n",
       "                                        Review_clean  \\\n",
       "0                                      [love, place]   \n",
       "1                                      [crust, good]   \n",
       "2                            [tasty, texture, nasty]   \n",
       "3  [stopped, late, bank, holiday, rick, steve, re...   \n",
       "4                    [selection, menu, great, price]   \n",
       "\n",
       "                                   Description_clean  \n",
       "0                                         love place  \n",
       "1                                         crust good  \n",
       "2                                tasty texture nasty  \n",
       "3  stopped late bank holiday rick steve recommend...  \n",
       "4                         selection menu great price  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_df = process(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_vec = clean_df['Review_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_vec = msg_vec.apply(lambda x: str(x).replace('[','').replace(']','').replace(',','')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_vec = msg_vec.apply(lambda x: x.replace('\\'',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['Description_clean'] = msg_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "959"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_vec.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Review_clean</th>\n",
       "      <th>Description_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>[love, place]</td>\n",
       "      <td>love place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>[crust, good]</td>\n",
       "      <td>crust good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>[tasty, texture, nasty]</td>\n",
       "      <td>tasty texture nasty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>[stopped, late, bank, holiday, rick, steve, re...</td>\n",
       "      <td>stopped late bank holiday rick steve recommend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>[selection, menu, great, price]</td>\n",
       "      <td>selection menu great price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>[think, food, flavor, texture, lacking]</td>\n",
       "      <td>think food flavor texture lacking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>[appetite, instantly]</td>\n",
       "      <td>appetite instantly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>[overall, impressed]</td>\n",
       "      <td>overall impressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>[experience, underwhelming, think, ninja, sush...</td>\n",
       "      <td>experience underwhelming think ninja sushi time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>[waste, life, pour, salt, wound, draw, time, b...</td>\n",
       "      <td>waste life pour salt wound draw time bring check</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  \\\n",
       "0                             Wow... Loved this place.   \n",
       "1                                   Crust is not good.   \n",
       "2            Not tasty and the texture was just nasty.   \n",
       "3    Stopped by during the late May bank holiday of...   \n",
       "4    The selection on the menu was great and so wer...   \n",
       "..                                                 ...   \n",
       "995  I think food should have flavor and texture an...   \n",
       "996                           Appetite instantly gone.   \n",
       "997  Overall I was not impressed and would not go b...   \n",
       "998  The whole experience was underwhelming, and I ...   \n",
       "999  Then, as if I hadn't wasted enough of my life ...   \n",
       "\n",
       "                                          Review_clean  \\\n",
       "0                                        [love, place]   \n",
       "1                                        [crust, good]   \n",
       "2                              [tasty, texture, nasty]   \n",
       "3    [stopped, late, bank, holiday, rick, steve, re...   \n",
       "4                      [selection, menu, great, price]   \n",
       "..                                                 ...   \n",
       "995            [think, food, flavor, texture, lacking]   \n",
       "996                              [appetite, instantly]   \n",
       "997                               [overall, impressed]   \n",
       "998  [experience, underwhelming, think, ninja, sush...   \n",
       "999  [waste, life, pour, salt, wound, draw, time, b...   \n",
       "\n",
       "                                     Description_clean  \n",
       "0                                           love place  \n",
       "1                                           crust good  \n",
       "2                                  tasty texture nasty  \n",
       "3    stopped late bank holiday rick steve recommend...  \n",
       "4                           selection menu great price  \n",
       "..                                                 ...  \n",
       "995                  think food flavor texture lacking  \n",
       "996                                 appetite instantly  \n",
       "997                                  overall impressed  \n",
       "998    experience underwhelming think ninja sushi time  \n",
       "999   waste life pour salt wound draw time bring check  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(msg_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.570131778717041 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# run clustering algorihtm\n",
    "import time\n",
    "start_time = time.time()\n",
    "true_k = k\n",
    "k_means = KMeans(n_clusters=true_k, init=init, max_iter=max_iter, n_init=n_init)\n",
    "kmeans_fit = k_means.fit(X)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = k_means.fit_predict(X)\n",
    "centroids = k_means.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def k_mean_distance(data, centroid_matrix, i_centroid, cluster_labels):\n",
    "    no_of_rec = data[cluster_labels == i_centroid].shape[0]\n",
    "    distances = [np.linalg.norm(x - centroid_matrix) for x in data[cluster_labels == i_centroid]]\n",
    "    wcss = sum(i * i for i in distances)\n",
    "    if no_of_rec != 0:\n",
    "        mean = wcss/no_of_rec\n",
    "    else:\n",
    "        mean = 0\n",
    "  \n",
    "    print('Cluster_id = {} & cluster_score = {} with No of records = {} & mean = {}'.format(i_centroid, wcss, no_of_rec, mean))\n",
    "    return round(wcss, 2), no_of_rec, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_goodness_score(clusters, centroids, emb_matrix):\n",
    "    print('Goodness score')\n",
    "    score = []\n",
    "    record_list = []\n",
    "    mean_list = []\n",
    "    for i, centroid_matrix in enumerate(centroids):\n",
    "        cs, no_of_rec, mean = k_mean_distance(emb_matrix, centroid_matrix, i, clusters)\n",
    "        score.append(cs)\n",
    "        record_list.append(no_of_rec)\n",
    "        mean_list.append(round(mean,2))\n",
    "    return score, record_list, mean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodness score\n",
      "Cluster_id = 0 & cluster_score = 130.89865157239936 with No of records = 133 & mean = 0.9842003877624012\n",
      "Cluster_id = 1 & cluster_score = 43.5191046788152 with No of records = 54 & mean = 0.8059093459039851\n",
      "Cluster_id = 2 & cluster_score = 13.972798203077916 with No of records = 21 & mean = 0.6653713430037103\n",
      "Cluster_id = 3 & cluster_score = 24.13944810202232 with No of records = 30 & mean = 0.8046482700674107\n",
      "Cluster_id = 4 & cluster_score = 15.526233846525987 with No of records = 21 & mean = 0.7393444688821899\n",
      "Cluster_id = 5 & cluster_score = 38.649566485761774 with No of records = 42 & mean = 0.9202277734705184\n",
      "Cluster_id = 6 & cluster_score = 15.065889123962386 with No of records = 18 & mean = 0.8369938402201326\n",
      "Cluster_id = 7 & cluster_score = 61.45373944409728 with No of records = 74 & mean = 0.830455938433747\n",
      "Cluster_id = 8 & cluster_score = 51.60897903674988 with No of records = 57 & mean = 0.9054206848552611\n",
      "Cluster_id = 9 & cluster_score = 270.5473139471869 with No of records = 290 & mean = 0.932921772231679\n",
      "Cluster_id = 10 & cluster_score = 7.86119222887909 with No of records = 11 & mean = 0.7146538389890081\n",
      "Cluster_id = 11 & cluster_score = 17.14346674843567 with No of records = 22 & mean = 0.7792484885652577\n",
      "Cluster_id = 12 & cluster_score = 4.354023155932571 with No of records = 10 & mean = 0.43540231559325704\n",
      "Cluster_id = 13 & cluster_score = 31.48507763231754 with No of records = 39 & mean = 0.807309682879937\n",
      "Cluster_id = 14 & cluster_score = 22.151728939923974 with No of records = 25 & mean = 0.8860691575969589\n",
      "Cluster_id = 15 & cluster_score = 60.826503052299095 with No of records = 71 & mean = 0.8567113105957619\n",
      "Cluster_id = 16 & cluster_score = 16.36170125070281 with No of records = 19 & mean = 0.8611421710896217\n",
      "Cluster_id = 17 & cluster_score = 9.850439296741717 with No of records = 15 & mean = 0.6566959531161145\n",
      "Cluster_id = 18 & cluster_score = 22.008772687897903 with No of records = 29 & mean = 0.7589231961344104\n",
      "Cluster_id = 19 & cluster_score = 15.755542749378199 with No of records = 19 & mean = 0.8292390920725368\n"
     ]
    }
   ],
   "source": [
    "score, record_list, mean_list = get_goodness_score(clusters, centroids, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "label = k_means.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_score = silhouette_score(X, label, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      "Label : know awesome friendly\n",
      "Cluster 1:\n",
      "Label : great food service\n",
      "Cluster 2:\n",
      "Label : wait minute hour\n",
      "Cluster 3:\n",
      "Label : come time probably\n",
      "Cluster 4:\n",
      "Label : amazing place absolutely\n",
      "Cluster 5:\n",
      "Label : eat feel dish\n",
      "Cluster 6:\n",
      "Label : menu worth drive\n",
      "Cluster 7:\n",
      "Label : good food service\n",
      "Cluster 8:\n",
      "Label : food time think\n",
      "Cluster 9:\n",
      "Label : love delicious star\n",
      "Cluster 10:\n",
      "Label : tasty good extremely\n",
      "Cluster 11:\n",
      "Label : nice restaurant server\n",
      "Cluster 12:\n",
      "Label : terrible service food\n",
      "Cluster 13:\n",
      "Label : service slow fantastic\n",
      "Cluster 14:\n",
      "Label : salad bring ask\n",
      "Cluster 15:\n",
      "Label : place love recommend\n",
      "Cluster 16:\n",
      "Label : order arrive minute\n",
      "Cluster 17:\n",
      "Label : definitely pay worth\n",
      "Cluster 18:\n",
      "Label : bad service food\n",
      "Cluster 19:\n",
      "Label : night perfect family\n"
     ]
    }
   ],
   "source": [
    "# topic modeling\n",
    "print(\"Top terms per cluster:\")\n",
    "val = []\n",
    "order_centroids = k_means.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(k):\n",
    "    print(\"Cluster %d:\" % i)\n",
    "    topic = ''\n",
    "    for ind in order_centroids[i, :3]:\n",
    "        topic = str(topic + ' ' + terms[ind]).strip()\n",
    "    print(\"Label : {}\".format(topic))\n",
    "\n",
    "    val.append(topic.replace(' ', '-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>know-awesome-friendly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great-food-service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wait-minute-hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>come-time-probably</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazing-place-absolutely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eat-feel-dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>menu-worth-drive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>good-food-service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>food-time-think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>love-delicious-star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tasty-good-extremely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nice-restaurant-server</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>terrible-service-food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>service-slow-fantastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>salad-bring-ask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>place-love-recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>order-arrive-minute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>definitely-pay-worth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bad-service-food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>night-perfect-family</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Topics\n",
       "0      know-awesome-friendly\n",
       "1         great-food-service\n",
       "2           wait-minute-hour\n",
       "3         come-time-probably\n",
       "4   amazing-place-absolutely\n",
       "5              eat-feel-dish\n",
       "6           menu-worth-drive\n",
       "7          good-food-service\n",
       "8            food-time-think\n",
       "9        love-delicious-star\n",
       "10      tasty-good-extremely\n",
       "11    nice-restaurant-server\n",
       "12     terrible-service-food\n",
       "13    service-slow-fantastic\n",
       "14           salad-bring-ask\n",
       "15      place-love-recommend\n",
       "16       order-arrive-minute\n",
       "17      definitely-pay-worth\n",
       "18          bad-service-food\n",
       "19      night-perfect-family"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics=pd.DataFrame(val, columns=['Topics'])\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | Topics                   |\n",
      "|----|--------------------------|\n",
      "|  0 | know-awesome-friendly    |\n",
      "|  1 | great-food-service       |\n",
      "|  2 | wait-minute-hour         |\n",
      "|  3 | come-time-probably       |\n",
      "|  4 | amazing-place-absolutely |\n",
      "|  5 | eat-feel-dish            |\n",
      "|  6 | menu-worth-drive         |\n",
      "|  7 | good-food-service        |\n",
      "|  8 | food-time-think          |\n",
      "|  9 | love-delicious-star      |\n",
      "| 10 | tasty-good-extremely     |\n",
      "| 11 | nice-restaurant-server   |\n",
      "| 12 | terrible-service-food    |\n",
      "| 13 | service-slow-fantastic   |\n",
      "| 14 | salad-bring-ask          |\n",
      "| 15 | place-love-recommend     |\n",
      "| 16 | order-arrive-minute      |\n",
      "| 17 | definitely-pay-worth     |\n",
      "| 18 | bad-service-food         |\n",
      "| 19 | night-perfect-family     |\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(topics, headers = 'keys', tablefmt = 'github'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results = pd.DataFrame()\n",
    "for slot in clean_df.columns:\n",
    "    cluster_results[slot] = clean_df[slot]\n",
    "kmeans_fit.labels_.shape\n",
    "cluster_results['cluster_id'] = kmeans_fit.labels_\n",
    "cluster_results['cluster_labels'] = cluster_results['cluster_id'].apply(lambda x: val[x])\n",
    "cluster_results['goodness_score'] = cluster_results['cluster_id'].apply(lambda x: mean_list[x])\n",
    "\n",
    "cluster_results['cluster_id'] = cluster_results['cluster_id'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results.sort_values(by='cluster_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Review_clean</th>\n",
       "      <th>Description_clean</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>cluster_labels</th>\n",
       "      <th>goodness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Bacon is hella salty.</td>\n",
       "      <td>[bacon, hella, salty]</td>\n",
       "      <td>bacon hella salty</td>\n",
       "      <td>0</td>\n",
       "      <td>know-awesome-friendly</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>The yellowtail carpaccio was melt in your mout...</td>\n",
       "      <td>[yellowtail, carpaccio, melt, mouth, fresh]</td>\n",
       "      <td>yellowtail carpaccio melt mouth fresh</td>\n",
       "      <td>0</td>\n",
       "      <td>know-awesome-friendly</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>The desserts were a bit strange.</td>\n",
       "      <td>[dessert, bit, strange]</td>\n",
       "      <td>dessert bit strange</td>\n",
       "      <td>0</td>\n",
       "      <td>know-awesome-friendly</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>Do not waste your money here!</td>\n",
       "      <td>[waste, money]</td>\n",
       "      <td>waste money</td>\n",
       "      <td>0</td>\n",
       "      <td>know-awesome-friendly</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>I know this is not like the other restaurants ...</td>\n",
       "      <td>[know, restaurant]</td>\n",
       "      <td>know restaurant</td>\n",
       "      <td>0</td>\n",
       "      <td>know-awesome-friendly</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>Tried to go here for lunch and it was a madhouse.</td>\n",
       "      <td>[try, lunch, madhouse]</td>\n",
       "      <td>try lunch madhouse</td>\n",
       "      <td>9</td>\n",
       "      <td>love-delicious-star</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>We were promptly greeted and seated.</td>\n",
       "      <td>[promptly, greet, seated]</td>\n",
       "      <td>promptly greet seated</td>\n",
       "      <td>9</td>\n",
       "      <td>love-delicious-star</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>Same evening, him and I are both drastically s...</td>\n",
       "      <td>[evening, drastically, sick]</td>\n",
       "      <td>evening drastically sick</td>\n",
       "      <td>9</td>\n",
       "      <td>love-delicious-star</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>Any grandmother can make a roasted chicken bet...</td>\n",
       "      <td>[grandmother, roast, chicken]</td>\n",
       "      <td>grandmother roast chicken</td>\n",
       "      <td>9</td>\n",
       "      <td>love-delicious-star</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Waitress was sweet and funny.</td>\n",
       "      <td>[waitress, sweet, funny]</td>\n",
       "      <td>waitress sweet funny</td>\n",
       "      <td>9</td>\n",
       "      <td>love-delicious-star</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  \\\n",
       "169                              Bacon is hella salty.   \n",
       "542  The yellowtail carpaccio was melt in your mout...   \n",
       "548                   The desserts were a bit strange.   \n",
       "821                      Do not waste your money here!   \n",
       "555  I know this is not like the other restaurants ...   \n",
       "..                                                 ...   \n",
       "636  Tried to go here for lunch and it was a madhouse.   \n",
       "635               We were promptly greeted and seated.   \n",
       "632  Same evening, him and I are both drastically s...   \n",
       "627  Any grandmother can make a roasted chicken bet...   \n",
       "499                      Waitress was sweet and funny.   \n",
       "\n",
       "                                    Review_clean  \\\n",
       "169                        [bacon, hella, salty]   \n",
       "542  [yellowtail, carpaccio, melt, mouth, fresh]   \n",
       "548                      [dessert, bit, strange]   \n",
       "821                               [waste, money]   \n",
       "555                           [know, restaurant]   \n",
       "..                                           ...   \n",
       "636                       [try, lunch, madhouse]   \n",
       "635                    [promptly, greet, seated]   \n",
       "632                 [evening, drastically, sick]   \n",
       "627                [grandmother, roast, chicken]   \n",
       "499                     [waitress, sweet, funny]   \n",
       "\n",
       "                         Description_clean cluster_id         cluster_labels  \\\n",
       "169                      bacon hella salty          0  know-awesome-friendly   \n",
       "542  yellowtail carpaccio melt mouth fresh          0  know-awesome-friendly   \n",
       "548                    dessert bit strange          0  know-awesome-friendly   \n",
       "821                            waste money          0  know-awesome-friendly   \n",
       "555                        know restaurant          0  know-awesome-friendly   \n",
       "..                                     ...        ...                    ...   \n",
       "636                     try lunch madhouse          9    love-delicious-star   \n",
       "635                  promptly greet seated          9    love-delicious-star   \n",
       "632               evening drastically sick          9    love-delicious-star   \n",
       "627              grandmother roast chicken          9    love-delicious-star   \n",
       "499                   waitress sweet funny          9    love-delicious-star   \n",
       "\n",
       "     goodness_score  \n",
       "169            0.98  \n",
       "542            0.98  \n",
       "548            0.98  \n",
       "821            0.98  \n",
       "555            0.98  \n",
       "..              ...  \n",
       "636            0.93  \n",
       "635            0.93  \n",
       "632            0.93  \n",
       "627            0.93  \n",
       "499            0.93  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
